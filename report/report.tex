% Created 2017-02-09 jeu. 02:21
% Intended LaTeX compiler: pdflatex
\documentclass{article}
\usepackage{natbib}
\usepackage[french]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{hyperref}
\usepackage{natbib}
\usepackage{amsmath,amssymb,amsthm,amsopn}
\usepackage{mathrsfs}
\usepackage{geometry}
\geometry{a4paper,left=2.5cm,top=2cm,right=2.5cm,bottom=2cm,marginparsep=7pt, marginparwidth=.6in}

\author{Li Honglin \\Maxime Buron}
\date{\today}
\title{Deep Structured Output Learning Dor Unconstrained Text Recognition}
\hypersetup{
 pdfauthor={Li Honglin Maxime Buron},
 pdftitle={Deep Structured Output Learning Dor Unconstrained Text Recognition},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 24.5.1 (Org mode 9.0)}, 
 pdflang={French}}
\begin{document}

\maketitle
\tableofcontents
\section{Résumé du papier}
Nous avons choisi de travailler sur le papier intitulé Deep Structured Output Learning Dor Unconstrained Text Recognition de Max Jaderberg, Karen Simonnyan, Andrea Vedaldi et Andrew Zisserman. Voici un résumé de ce que nous en avons compris. L'article présente trois méthodes pour résoudre le problème suivant, dont la dernière combine les deux premières.
\subsection{introduction du problème}
Ce papier s'attaque au problème très général suivant : détecter et reconnaître du texte sur une image. Plus précisément, ce papier suppose la phase de détection est déjà réalisée, en d'autres termes l'on ne considère que des images contenant uniquement un seul mot sans autre contenu. Le sujet principal est donc la reconnaissance de mot, et particulièrement de mot sans contrainte, c'est à dire des mots qui ne sont pas obligatoirement issue d'une liste de vocabulaires.

\subsection{encodage de l'entrée}
Comme dit précedemment, l'entrée du problème est un image, seulement pour des questions de standardisation, notre algorithme nécessite des images de taille fixe $32\times100$ en noir et blanc. Malheuresement les images des ensembles de données ne sont pas toutes la même taille, c'est pourquoi elle sont étirées pour atteindre ces dimensions et cela sans préserver les proportions. Les images, une fois chargée sous forme de matrices de dimension $32 \times 100$ sont normalisées en leur soustrayant leur moyenne et en les divisant par leur écart type. 

\subsection{l'approche par caractère}
L'approche par caractère considère que chaque caractère identifié selon sa position indépendemment des autres caractères. 

La modélisation de la sortie de l'algorithme est une liste de $N_{max}$ distribution de probabilités,où $N_{max}$ est la longueur maximale qu'un mot sur une image en entrée. Les distribution de probalités modèlisent les lois de variables aléatoires à valeurs dans l'alphabet considèré pour identifier les mots augmenté par un caractère vide $\phi$. Un mot $\omega$ composé des caractères $c_1c_2\dotsc_n$ avec $n\leq N_{max}$ est encodé par la suite de $N_{max}$ caractères suivantes $c_1, c_2, \dots,c_n,\phi,\dots,\phi$. La prédiction de l'algorithme pour une image donnée $x$ est alors l'encodage $\omega^*$ défini par :
$$ \omega^* = \text{arg} \max_{\omega} P(w|x) = \text{arg} \max_{c_1, c_2, \dots,c_{N_{max}}} \prod_{i=1}^{N_{max}} P(c_i|\Phi(x))$$
où $\Phi(x)$ est un ensemble de paramètres.

L'algorithme du calcul des distributions est constitué d'un réseau de neurore conditionnel, qui sera réutiliser dans la 

\subsection{l'approche par sac de mots}

\subsection{l'approche jointe}

\subsection{les différents ensembles de données}

\section{La méthode choisie}

\section{L'implémentation}

\section{Les résultats}

\section{Conclusion}

\end{document}
